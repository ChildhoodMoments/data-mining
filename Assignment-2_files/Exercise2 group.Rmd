---
title: "Exercise2"
author: "Jonathan"
date: "3/7/2022"
output: md_document
---
Author:
LiZhao Du
YiJi Gao
Jyun-Yu Cheng


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Question 1
```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(RCurl)
library(tidyverse)
library(mosaic)
library(curl)
library(ggplot2)
capmetro_UT = read.csv('https://raw.githubusercontent.com/jgscott/ECO395M/master/data/capmetro_UT.csv')
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}

capmetro_UT = mutate(capmetro_UT,
                     day_of_week = factor(day_of_week,
                     levels=c("Mon", "Tue", "Wed","Thu", "Fri", "Sat", "Sun")),
                     month = factor(month, levels=c("Sep", "Oct","Nov")))

```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
average_boarding = capmetro_UT %>%
  group_by(hour_of_day, day_of_week, month) %>%
  summarize(mean_boarding = mean(boarding)) 
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#add a new variable which is called "week" to separate the weekday and weekend
week = mutate(capmetro_UT, weekdays = day_of_week == "Mon", "Tue", "Wed","Thu", "Fri", weekend = day_of_week == "Sat", "Sun")
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}

ggplot(average_boarding) +
  geom_line(aes(x = hour_of_day, y=mean_boarding, color=month)) +
  facet_wrap(~day_of_week) +
  labs(title="Average boardings grouped by hour of the day, day of week, and month", y="Mean_boarding", x="Hour of day") +
  scale_color_manual(values = c('blue','red','green')) 

head(capmetro_UT)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
# graph2
average_boarding_temperature = capmetro_UT %>%
  group_by(temperature, hour_of_day,  weekend) %>%
  summarize(mean_boarding = mean(boarding)) 
average_boarding_temperature

ggplot(average_boarding_temperature) +
  geom_point(aes(x = temperature, y=mean_boarding, color=weekend)) +
  facet_wrap(~hour_of_day) +
  labs(title="Average boardings grouped by temperature and week", y="Mean boarding", x="Temperature") +
  scale_color_manual(values = c('darkblue','darkgreen'))
```
Problem1:
(1)The hour of peak of boarding is almost the same from day to day, its range is about from 4 p.m. to 5 p.m.

(2)The reason that average boarding on Mondays in September look lower, compared to other days and months, is the summer break just finish, so not all the students come back.

(3)The reason that average boarding on Weds/Thurs/Fri in November look lower is because of the Thanksgiving holiday , which lower the the average boarding of November.

Problem2:
When we hold hour of day and weekend status constant, temperature seems have not an noticeable effect on the number of UT students riding the bus,the line is horizontal.


# Question 2 
```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(knitr)
data("SaratogaHouses")
```

## build better model

```{r,echo=FALSE, message= FALSE, warning=FALSE}
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
```

we try three different models, and calculate the RMSE

```{r,echo=FALSE, message= FALSE, warning=FALSE}
lm1 = lm(price ~ lotSize + lotSize:age + age + 
           landValue + bathrooms + sewer + centralAir, data=saratoga_train)
lm2 = lm(price ~ lotSize + age + log(landValue) + log(livingArea) + 
           bedrooms + bathrooms +  bedrooms:bathrooms + 
           rooms + centralAir, data=saratoga_train)
lm3 = lm(price ~  lotSize + age + log(landValue) 
         + log(livingArea) + log(landValue):log(livingArea) 
         + bedrooms + bathrooms + rooms + centralAir 
         + fireplaces:waterfront, data=saratoga_train)
```

model_1 : lm(price ~ lotSize + lotSize:age + age + 
               landValue + bathrooms + sewer + centralAir, data=saratoga_train)

model_2 : lm(price ~ lotSize + age + log(landValue) + log(livingArea) + 
               bedrooms + bathrooms +  bedrooms:bathrooms + 
               rooms + centralAir, data=saratoga_train)

model_3 : lm(price ~ lotSize + age + log(landValue) + log(livingArea) log(landValue):log(livingArea) + bedrooms + bathrooms + rooms + centralAir +      fireplaces:waterfront, data = saratoga_train)



and we can get their out of sample's RMSE like:
```{r,echo=FALSE, message= FALSE, warning=FALSE}
rmse(lm1, saratoga_test)
rmse(lm2, saratoga_test)
rmse(lm3, saratoga_test)  
```
so I think model_3 is best model I can get from linear model

build the best K-nearest-neighbor regression model for price
I also use the same variables I used in model_3

```{r,echo=FALSE, message= FALSE, warning=FALSE}
k_folds = 5
SaratogaHouses_folds = crossv_kfold(SaratogaHouses, k=k_folds)
k_grid = c(25:125)
cv_SaratogaHouses = foreach(k = k_grid, .combine='rbind') %dopar% {
  models = map(SaratogaHouses_folds$train, ~ knnreg(log(price) ~ log(landValue) + log(livingArea) + log(landValue):log(livingArea) + bedrooms + bathrooms + rooms + centralAir + fireplaces:waterfront, k=k, data = ., use.all=FALSE))
  errs = map2_dbl(models, SaratogaHouses_folds$test, modelr::rmse)
  c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(k_folds))
} %>% as.data.frame
knn_k <- ggplot(cv_SaratogaHouses) + 
  geom_point(aes(x= k, y= err),size = 1) + 
  geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err))+
  geom_line(aes(x= k, y= err),size = 0.8)
```

we can get the best k as:
```{r,echo=FALSE, message= FALSE, warning=FALSE}
k_min_rmse = cv_SaratogaHouses %>%
  slice_min(err) %>%
  pull(k)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
k_min_rmse
```

then We calculate the knn method RMSE

```{r,echo=FALSE, message= FALSE, warning=FALSE}
knn_SaratogaHouses_predict = knnreg(log(price) ~ log(landValue) + log(livingArea) + log(landValue):log(livingArea) + bedrooms + bathrooms + rooms + centralAir + fireplaces:waterfront, data=saratoga_train, k=k_min_rmse)
RMSE_knn = rmse(knn_SaratogaHouses_predict, saratoga_test)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
RMSE_knn
```


then averaging the estimate of out-of-sample RMSE over many different random train/test splits, either randomly or by cross-validation.

```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(parallel)
rmse_sim = do(20)*{
  # fresh train/test split
  sara_split =  initial_split(SaratogaHouses, prop=0.8)
  sara_train = training(sara_split)
  sara_test  = testing(sara_split)
  
  # refit our models to this particular split
  # we're using "update" here to avoid having to type out the giant model formulas
lm1 = update(lm1, data=sara_train)
lm2 = update(lm2, data=sara_train)
lm3 = update(lm3, data=sara_train)

# collect the model errors in a single vector
model_errors = c(rmse(lm1, sara_test), rmse(lm2, sara_test), rmse(lm3, sara_test))

# return the model errors
model_errors
}
```

# Question 3 Classification and retrospective sampling

first we input dataset and make a bar plot of default probability by credit history,
Make a bar plot of default probability by credit history

```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
german_credit <- read.csv('https://raw.githubusercontent.com/jgscott/ECO395M/master/data/german_credit.csv')
table_default_history <-  as.data.frame(table(german_credit$Default, german_credit$history))
prob_default <- german_credit%>%group_by(Default, history) %>% summarise(n = n())%>% 
  group_by(history) %>%mutate(feq = n/sum(n))
barplot_default <- ggplot(data = prob_default)+
  geom_bar(mapping = aes(x = history, y = feq, fill = factor(Default)), position = 'dodge',stat='identity')+
  #must add stat = 'identity' basically telling ggplot2 you will provide the y-values for the barplot, 
  #rather than counting the aggregate number of rows for each x value, which is the default stat=count
  #https://stackoverflow.com/questions/61068031/error-stat-count-can-only-have-an-x-or-y-aesthetic
  labs(title = "probability of default based on their own history ")+
  labs(x = 'history', y = 'probability')
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
plot(barplot_default)
```

then build a logistic regression model for predicting default probability

```{r,echo=FALSE, message= FALSE, warning=FALSE}
logit_history = glm(Default~duration + amount + installment + age + history + purpose + foreign, data = german_credit, family = 'binomial')
```


```{r,echo=FALSE, message= FALSE, warning=FALSE}
summary(logit_history)
```

We can see the result that coefficent of history: poor and terible history have a huge negative effect on Default.Check the statstical significant for these variables, it shows they are statistical significant

I don't think this data set is appropiate for building a predictive model, since bank sampled a set of loans that had defaulted for inclusion in the study.


# Question 4

```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(modelr)
library(rsample)
library(mosaic)
library(lubridate)
library(ModelMetrics)


#hotels_dev <- read.csv('https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv')

#hotels_val <- read.csv('https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv')
hotels_dev <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
hotels_val <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")

# Using only the data in hotels.dev.csv, please compare the out-of-sample performance of the following models:

hotels_dev = mutate(hotels_dev, Time = ymd(arrival_date), month = month(Time) %>% factor())
hotels_val = mutate(hotels_val, Time = ymd(arrival_date), month = month(Time) %>% factor())

hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_split_train = training(hotels_dev_split)
hotels_dev_split_test = testing(hotels_dev_split)

# baseline 1: a small model that uses only the market_segment, adults, customer_type, and is_repeated_guest variables as features.
lm1 = lm(children ~ market_segment + adults + customer_type + is_repeated_guest,  data = hotels_dev_split_train,)
lm2 = lm(children ~ . -arrival_date, data = hotels_dev_split_train,)
# transfer arrival_date  as a time stamp,  in a specific format: Y-M-D    feature-engineer.R

lm3 = lm(children ~ . -arrival_date + market_segment:distribution_channel + month, data = hotels_dev_split_train,)

glm1 = glm(children ~ market_segment + adults + customer_type + is_repeated_guest,  data = hotels_dev_split_train, family = 'binomial')
glm2 = glm(children ~ . -arrival_date, data = hotels_dev_split_train, family = 'binomial')
glm3 = glm(children ~ . -arrival_date + market_segment:distribution_channel + month, data = hotels_dev_split_train, family = 'binomial')

rmse(lm1, hotels_dev_split_test)
rmse(lm2, hotels_dev_split_test)
rmse(lm3, hotels_dev_split_test)
rmse(glm1, hotels_dev_split_test)
rmse(glm2, hotels_dev_split_test)
rmse(glm3, hotels_dev_split_test)

# it shows prediction from a rank-deficient fit may be misleading
# lm model's rmse is smaller than glm model's



#Model validation: step 1
# spamtoy.R

probhat = predict(lm3, newdata = hotels_val)
probs <- exp(probhat)/(1 + exp(probhat))

probhat_2 <- predict(glm3, newdata = hotels_val)



# or get probability directly use
#pred = predict(glm3, newdata = hotels_val, type = 'response')
#head(pred)

#children_hat =  ifelse(probhat >= 0.5, 1, 0)
#table(children = hotels_val$children, children_hat = children_hat)


library(ROCR)

# ROC curve
#https://www.bilibili.com/video/BV1Y64y1Z7Ht
ROCR = prediction(probhat, hotels_val$children)
perf = performance(ROCR, 'tpr','fpr')

ROCR_2 = prediction(probhat_2, hotels_val$children)
perf_2 = performance(ROCR_2, 'tpr', 'fpr')

x <- unlist(perf@x.values)
y <- unlist(perf@y.values)
plotdata <- data.frame(x,y)
names(plotdata) <- c('x', 'y')

g <- ggplot(plotdata)+ 
  geom_path(aes(x = x, y = y, color = x), size =1)+
  labs(x = 'False positive rate', y = 'True positive rate', title = 'ROC Curves based on linear model')

x_2 <- unlist(perf_2@x.values)
y_2 <- unlist(perf_2@y.values)
plotdata_2 <- data.frame(x_2,y_2)
names(plotdata_2) <- c('x_2', 'y_2')

g_2  <- ggplot(plotdata_2)+ 
  geom_path(aes(x = x_2, y = y_2, color = x_2), size =1)+
  labs(x = 'False positive rate', y = 'True positive rate', title = 'ROC Curves based on logit model')



# folds lecture 0207

# B
hotels_val_split = initial_split(hotels_val, prop = 0.8)
hotels_val_split_train = training(hotels_val_split)
hotels_val_split_test = testing(hotels_val_split)
library(caret)

set.seed(100)
indexs = createFolds(1:dim(hotels_val)[1], k = 20, list = TRUE, returnTrain = FALSE)
err_result = c()
model = glm(children ~ . -arrival_date + market_segment:distribution_channel + month, data = hotels_val, family = 'binomial')
for (i in 1:20){
  slice_data = hotels_val[indexs[[i]],]
  prediction = predict(model,newdata = slice_data,type = "response")
  predict_num = round(mean(prediction)*dim(slice_data)[1])
  ### expected number of bookings with children for that fold.
  actual_num = sum(slice_data$children)
  err_result = rbind(err_result,c(actual_num,predict_num))
} 

# The following is the summary of expected number of bookings with children for that 
# fold and actual number

err_result = data.frame(err_result)
colnames(err_result)=c("actual_num","predict_num") 
err_result$difference = err_result$predict_num-err_result$actual_num
print(err_result)

# The following figure demonstrates the distribution of difference beween actual number
# and expected number.
p0 = ggplot(data=err_result) + 
  geom_histogram(aes(x=difference)) 
p0
```

Not good. The prediction isn't accurate. Both numbers always move in the same direction, but the actual numbers wiggle more than predict number.




