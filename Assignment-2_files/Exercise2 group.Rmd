---
title: "Exercise2"
author: "Jonathan"
date: "3/7/2022"
output: md_document
---
Author:
LiZhao Du
YiJi Gao
Jyun-Yu Cheng


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


## Question 1
```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(RCurl)
library(ggplot2)
capmetro_UT = read.csv('https://raw.githubusercontent.com/jgscott/ECO395M/master/data/capmetro_UT.csv')
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#把categorical variables按合理的排列，不按字母順序排
#mutate用來新增資料框（衍生變數or非衍生變數都可以）
capmetro_UT = mutate(capmetro_UT,
                     day_of_week = factor(day_of_week,
                     levels=c("Mon", "Tue", "Wed","Thu", "Fri", "Sat", "Sun")),
                     month = factor(month, levels=c("Sep", "Oct","Nov")))

```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#calculate the average boarding time by group
#summarize 中輸入摘要對象的資料框(capmetro_UT，以及欲摘要的變數名稱（mean)
#先把campmetro_UT按hour of day, day of week,month去分群(by group_by，再使用summarize去計算mean(by summarize),命名為meanboarding

average_boarding = capmetro_UT %>%
  group_by(hour_of_day, day_of_week, month) %>%
  summarize(mean_boarding = mean(boarding)) 
average_boarding
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#add a new variable which is called "week" to separate the weekday and weekend
week = mutate(capmetro_UT, weekdays = day_of_week == "Mon", "Tue", "Wed","Thu", "Fri", weekend = day_of_week == "Sat", "Sun")
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#graph 1
#geom_line後面是規定x軸、y軸,color
#facet_wrap是將圖照day_of_week去分類
#scale_color_manual是更改線的顏色
ggplot(average_boarding) +
  geom_line(aes(x = hour_of_day, y=mean_boarding, color=month)) +
  facet_wrap(~day_of_week) +
  labs(title="Average boardings grouped by hour of the day, day of week, and month", y="Mean_boarding", x="Hour of day") +
  scale_color_manual(values = c('blue','red','green')) 

head(capmetro_UT)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
# graph2
average_boarding_temperature = capmetro_UT %>%
  group_by(temperature, hour_of_day,  weekend) %>%
  summarize(mean_boarding = mean(boarding)) 
average_boarding_temperature

ggplot(average_boarding_temperature) +
  geom_point(aes(x = temperature, y=mean_boarding, color=weekend)) +
  facet_wrap(~hour_of_day) +
  labs(title="Average boardings grouped by temperature and week", y="Mean boarding", x="Temperature") +
  scale_color_manual(values = c('darkblue','darkgreen'))
```
Problem1:
(1)The hour of peak of boarding is almost the same from day to day, its range is about from 4 p.m. to 5 p.m.

(2)The reason that average boarding on Mondays in September look lower, compared to other days and months, is the summer break just finish, so not all the students come back.

(3)The reason that average boarding on Weds/Thurs/Fri in November look lower is because of the Thanksgiving holiday , which lower the the average boarding of November.

Problem2:
When we hold hour of day and weekend status constant, temperature seems have not an noticeable effect on the number of UT students riding the bus,the line is horizontal.


## Question 4
```{r,echo=FALSE, message= FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(mosaic)
library(rsample)
library(parallel)
library(foreach)
library(gamlr)
library(modelr)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
# Read the data
hotels_dev = read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_dev.csv")
hotels_val = read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/hotels_val.csv")
hotels_dev = hotels_dev %>% filter(reserved_room_type != "L") 
head(hotels_dev)
head(hotels_val)

ggplot(data = hotels_dev) +
  geom_histogram(aes(x=children), binwidth=0.3,color = "blue" )
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
### Step 1. Model building
hotels_dev_split = initial_split(hotels_dev, prop = 0.7)
hotels_dev_train = training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
## <1> Build the Models

### Model1: only uses the market_segment, adults, customer_type, and is_repeated_guest variables as features
baselinemodel1 = glm(children ~ market_segment + adults + customer_type + is_repeated_guest,
                     data = hotels_dev_train, family = "binomial")

### Model2: uses all the possible predictors except the arrival_date variable
baselinemodel2 = glm(children ~ . - arrival_date , data = hotels_dev_train, family = "binomial")

### Model3: build the best model - use stepwise selection 
###start with a resonable guess: we use market_segment, adults, customer_type as features
guessmodel = glm(children ~ market_segment + adults + customer_type + is_repeated_guest + reserved_room_type + assigned_room_type,
                 data = hotels_dev_train, family = "binomial")
bestmodel2 = step(guessmodel, 
                  scope=~(.)^2)
getCall(bestmodel2)
coef(bestmodel2)
###assess the out-of-sample performance of the 3 models
rmse(baselinemodel1, hotels_dev_train)
rmse(baselinemodel2, hotels_dev_train)
rmse(bestmodel2, hotels_dev_train)
```
My model didn't perform well.
In the new dataset, rmse of new set is smaller than rmse of split set, but still close. The rmse of baseline1 is still the lowest.

# Model validation: step 1 
```{r,echo=FALSE, message= FALSE, warning=FALSE}
#prediction with validation set
phat_predict_bestmodel = predict(bestmodel2,hotels_val,type = "response")
# calculate TPR(t) versus FPR(t) as vary the classification threshold t.
t_grid = rep(1:49)/50
ROC_def = foreach(t = t_grid, .combine='rbind') %dopar% {
  yhat_best = ifelse(phat_predict_bestmodel > t, 1, 0)
  confusion_best = table(y=hotels_val$children, yhat=yhat_best)
  TPR_best = confusion_best[2,2]/(confusion_best[2,2]+confusion_best[2,1]) %>% round(3)
  FPR_best = confusion_best[1,2]/(confusion_best[1,1]+confusion_best[1,2]) %>% round(3)
  c(t=t, TPR = TPR_best, FPR = FPR_best)
} %>% as.data.frame()
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#plot the graph
ggplot(ROC_def) +
  geom_line(aes(x=t, y=TPR, color = "TPR"), size=1) +
  geom_line(aes(x=t, y=FPR, color = "FPR"), size=1) +
  labs(y="TPR/FPR", x = "t", color=" ")

#True ROC curve
ggplot(ROC_def) +
  geom_line(aes(x=FPR, y=TPR), size=1) +
  labs(y="TPR", x = "FPR", color=" ")
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
# Model validation: step 2
#create 20 folds of hotel_val
K_folds = 20

hotels_val = hotels_val %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(hotels_val)) %>% sample)
#predict whether each booking will have children on it
hotels_val_cv = foreach(fold = 1:K_folds, .combine='rbind') %dopar% {
  hotels_val_folds_train = filter(hotels_val, fold_id == fold)
  hotels_val_folds_phat = predict(bestmodel2, hotels_val_folds_train, type = "response")
  c(y=sum(hotels_val_folds_train$children), Expected_y=sum(hotels_val_folds_phat)%>%round(0))
} %>% as.data.frame()

hotels_val_cv = hotels_val_cv %>%
  mutate(fold_id = rep(1:K_folds))
```

```{r,echo=FALSE, message= FALSE, warning=FALSE}
#compare the expected number with actual number of booking with children 
ggplot(data = hotels_val_cv) +
  geom_line(aes(x = fold_id, y = y, color = "Actual"),  size = 1) +
  geom_line(aes(x = fold_id, y = Expected_y, color = "Expected"), size = 1) +
  labs(y="Predicted and Actual Children for Each Fold", x = "t", color=" ")+
  geom_point(aes(x = fold_id, y=y)) +
  geom_point(aes(x = fold_id, y=Expected_y))
```
Not good. The predict isn't accurate. Both numbers always move in the same direction, but the actual numbers wiggle more than predict number.

